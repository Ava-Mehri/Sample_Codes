## MDP.ipynb
GitHub: https://github.com/Ava-Mehri/Sample_Codes/blob/main/MDP/MDP.ipynb
* Solves a Markov decision process problem for a generic grid world using **Value Iteration Algorithm** and **Policy Iteration Algorithm**
* The input to run this code is [mdp_input.txt](https://github.com/Ava-Mehri/Sample_Codes/blob/main/MDP/mdp_input.txt)
* Works for any other grid world
* Input file lines:
    * The sizee of the world
    * Wall coordinates
    * Goal coordinates and their corresponding rewards
    * Reward per each step
    * Transition probabilities
    * Discount rate
    * Epsilon
 * The output is the optimal policy for each algorithm
